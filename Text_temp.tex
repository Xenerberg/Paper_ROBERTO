\section{Introduction}
% 1,25 pp, including abstract and figure 1
%
Among the possible applications of robotic systems in an orbital scenario, this paper focusses on those which may operate in On-Orbit Servicing and in Active Debris Removal missions~\cite{932685}\cite{doi: 10.1117/12.499871}\cite{dlr63555}\cite{telaar2017gnc}. To tackle the related control challenges we present here an autonomy-based approach, in which the robot is commanded through a precomputed reference trajectory, corrected by a tracking controller, to account for intrinsic planning and execution errors. We focus on the task of grasping a defective, tumbling target satellite (from here on, the Target) by means of a free-floating robot, consisting of a non-actuated chaser satellite (from here on, the Chaser) carrying a kinematically redundant robot manipulator. These are shown in Fig.~\ref{fig:facility}.

The task of grasping a target satellite with a space robot was already performed in \cite{932685} and \cite{doi: 10.1117/12.499871}, however only for the case of a cooperative Target. When the Target cannot be attitude controlled and does not present visual or structural features to aid its grasping, then it is generally termed non-cooperative. In this case, the accomplishment of the robotic grasping task in autonomous mode presents some substantial challenges. The robot motion is dictated by that of the Target, which is generally unknown. The robot motion also has to be correctly synchronized with that of the Target, in order to meet and grasp some preselected grasping point on it, while satisfying motion constraints, such as workspace limits, kinematic and dynamic singularities, collision avoidance, as well as sensor-driven constraints, such as camera field-of-view boundaries and pixel velocity limits. Furthermore, due to the given free-floating dynamics in play, the effect of an impact during the contact phase can be very detrimental for accomplishing the task, since it can quickly bring the Target out of the range of the robot.

The grasping task of interest has been addressed extensively in the literature, first in the context of feedback control and then also in that of optimal control (see Section~\ref{sec:related_work}). While in the former the aim is to solve a regulation control problem, often taking advantage of the free-floating dynamics and redundancy of the Chaser, in the latter an open-loop approach is preferred, based on the idea of computing a feasible and optimal trajectory in real-time. Due to the highly constrained task, explained above, the use of a feasible trajectory is recognized to be of great importance.
\begin{figure}[t!]
\psfrag{x_1}[cc][cc][\FontFigBBB]{{\color{white}$\{\mathcal{I}\}$}}
\psfrag{t}[cc][cc][\FontFigBBB]{{\color{black}$\{\mathcal{T}\}$}}
\psfrag{g}[cc][cc][\FontFigBBB]{{\color{black}$\{\mathcal{G}\}$}}
\psfrag{e}[cc][cc][\FontFigBBB]{{\color{black}$\{\mathcal{E}\}$}}
\psfrag{b}[cc][cc][\FontFigBBB]{{\color{white}$\{\mathcal{B}\}$}}
\psfrag{q}[cc][cc][\FontFigBB]{{\color{black}$q$}}
\psfrag{r}[cc][cc][\FontFigBB]{{\color{black}$r$}}
\psfrag{g_pose}[cc][cc][\FontFigBB]{{\color{black}$\begin{bmatrix}\eta_t,~ \rho_t \end{bmatrix}$}}
\psfrag{camera}[cc][cc][\FontFigBB]{{\color{black}$\begin{bmatrix}\mu,~ r_c \end{bmatrix}$}}
\psfrag{c_pose}[cc][cc][\FontFigBB]{{\color{black}$\begin{bmatrix}\eta_c,~ \rho_c \end{bmatrix}$}}
\psfrag{t_pose}[cc][cc][\FontFigBB]{{\color{black}$\begin{bmatrix}q,~ r \end{bmatrix}$}}
\centering\includegraphics[angle=0,width=0.47\textwidth]{./figures/motiv}
\caption{OOS-SIM experimental facility used to reproduce the gravity-free dynamics of the Chaser (left), carrying a Light-Weight Robot, and the Target (right). A camera is mounted on the gripper of the kinematically redundant manipulator, to allow visual servoing. The reference frames of the Chaser $\mathcal{B}$, the robot end-effector $\mathcal{\epsilon}$, the Target $\mathcal{T}$ and the predefined grasping point $\mathcal{G}$ are also shown.}
\label{fig:facility}
%\vspace{-10pt}
\end{figure}

A gap in the methodology described above, which we want to close here, is that of having both the optimal control and the feedback control elements working together. A feedback controller alone does not provide any guarantee of convergence, given the presence of the constraints, which give rise to local minima. Furthermore, the grasping task has a limited time window for its execution and local control methods generally do not ensure finite time convergence. At the same time, an open-loop approach is not robust to modelling errors (e.g., dynamic model) and to contingencies, such as an impact. We present here a tracking controller for executing the grasping task of interest, which takes a reference trajectory from a database, generated off-line with a motion planner in simulation and feasible with respect to all relevant constraints, and superimpose on it sensor-based corrections to account for the discrepancy between the simulated and the real world.

The first phase of the task, the approach phase, is executed by a visual servo in a cascade with an impedance controller, bringing the robot end-effector onto the grasping point on the tumbling Target. It is widely recognized that the robustness of a visual servo is significantly improved against modelling errors when performing tracking rather than regulation~\cite{siciliano2016springer}. The pose of the Target is robustly estimated throughout the motion with an extended Kalman filter, which is fed with the noisy pose estimates of a model-based visual tracking algorithm. The Kalman filter is designed to reduce its computational footprint, in view of an implementation on a realtime system. The use of robot impedance control is intended to minimize the detrimental effect of an impact between the robot manipulator and the Target. In the following rigidization phase of the grasping task, in which the Target is already grasped but needs to be stabilized with respect to the Chaser, the reference trajectory provides a final configuration in which to let the system drift with decaying velocity, by virtue of the robot manipulator controller's dissipation.

In this paper we present the tracking controller just described and its validation on DLR's OOS-SIM robotic facility, shown in Fig.~\ref{fig:facility}. This facility allows reproducing realistic orbital gravity-free dynamics in three-dimensions through hardware-in-the-loop simulation. The success of the controller requires a judicious interplay between the different elements involved: the motion planner, the visual servo (including the Kalman filter and the visual tracking) and the free-floating robot impedance controller. Furthermore, the intrinsic uncertainty in the control problem at hand is handled with partial on-line adaptation of the reference trajectory. Extensions of the functionality of the OOS-SIM facility to simulate the post-grasping tumbling motion of the satellite stack are also described.

The paper is then structures as follows. In the rest of this Section, we present a relevant bibliography and a more detailed problem statement. In Section~\ref{sec:methods} we provide details of the applied methods, while in Section ??? we present the experimental results and their analysis. In Section ??? we provide a discussion as well as our conclusions and views on future work. The mathematical notation is such that ??? CHECK
%
\subsection{Related work}
\label{sec:related_work}
%
Many approaches for grasping a free-tumbling Target mostly focus on feedback control methods~\cite{moosavian2007free}\cite{papadopoulos1994dynamics} \cite{dlr96736} and momentum control methods~\cite{yoshida2006capture}. In~\cite{aghili2012prediction}, the motion planning problem is solved for the approach phase of the grasping task. The planning is supported by a prediction of the Target's motion, achieved through an extended Kalman filter and noisy pose measurements of a laser camera system. The motion prediction occurs before any motion of the robot and the control strategy does not include a continuous visual feedback. An optimization problem is solved partly analytically and partly numerically, to minimize a penaltly cost, function of four weighted quantities: travel time, distance, line-of-sight angle of the laser camera and robot joint acceleration. The optimal control for the capturing maneuver is solved in the operational space of the robot manipulator and the robot manipulator kinematics and dynamics are as such not considered. Experiments are conducted on an experimental facility which reproduces the dynamics of the tumbling Target and of a robot manipulator end-effector with an attitude-controlled base. In~\cite{aghili2009optimal} a path planning method is presented for the rigidization phase which follows the grasping. It is assumed that the Chaser is attitude stabilized. As such, an optimal control problem is formulated for the detumbling of the Target to which an external moment is applied, solved analytically for the case of minimum time and zero final velocity.

In~\cite{flores2013optimal} an optimal control problem is solved numerically with nonlinear optimization in joint space, addressing the grasping task under the uncertainty of the initial and final positions of the robot end-effector resulting from tracking sensing data. The uncertainly is treated with the Markov Chain Monte Carlo method, which provides an approximation of the expected value of the optimal robot trajectory, in function of a given probabiblity distribution for the uncertainty. The method is applied in simulation to a 2D problem, for a fully attitude controlled robotic system. In~\cite{lampariello2013generating} the motion planning task is solved numerically within nonlinear optimization, with a direct shooting method. The problem is treated in 3D and with inclusion of robot joint position and velocities contraints, as well as the Chaser free-floating dynamics. A look-up table approach is presented with which (close to) globally optimal soultions can be retreived in real-time for any possible tumbling state of the Target within a predefined range for the angular velocity. 
%
%Hrishik and Nassir
%Visual Servoing on ETS-VII [Yoshida] and Orbital Express with markers on Target and inverse kinematics resolution (CHECK and expand). One of the first works which included the use of visual servoing in an experimental setup was [Aghili]. Here, the optimal control described in [] was applied on-line under realistic lighting conditions to grasp and stabilize a tumbling target. In [HIT14-timedelayedVS] the grasping task was treated with emphasis on the time delay introduced by the visual servo in the control loop (approximately 500-750ms). The visual servo, which provides pose information between a visual marker on the target and the eye-in-hand camera on the tip of the robot manipulator, was tested on a hardware-in-the-loop robotic facility on ground. The latter consisted of two industrial robots, which emulated the free-floating dynamics of the two satellites, by virtue of a dynamic simulation model (as in [Aghili]). 

In \cite{Aghili07}, an adaptive EKF variant was developed which used Laser-vision data for parameter and motion estimation. The authors used this variant for a Prediction-planning-execution approach controller in \cite{Aghili08}. In \cite{Dubowsky}, the authors implemented a cascade of two filters using range images for similar objectives of target state, shape and inertia estimation. In \cite{DLR01}, a long-term prediction method was adopted keeping autonomous grasping in focus. In \cite{RIS0}, a closed-loop control system was implemented for autonomous target tracking with visual servo and EKF as a part of the incremental inverse-kinematics controller. Based on the formalism presented in \cite{Aghili07}, an EKF architecture was developed in \cite{Selfthesis} and is implemented on the OOS-Sim facility.The idea of Visual servoing and position-based impedance control were brought together in \cite{Lippiello}, for tasks in which contact with the environment is expected. As such, the aim here was to fuse the visual, joint position and other sensory information to improve the accuracy of the estimation of the target object pose and hence improve accuracy in tracking. Model-based methods~\cite{Comport2004, Drummond2002} which exploit robust edge features efficently, are used in position-based control. The edge-based method~\cite{Drummond2002} presents a direct and accurate formulation for minimizing the reprojection error from 3D to 2D~\cite{Oumer2015}. 
%
%
%Todos:
%- A. Flores-Abad et al., Optimal Control of a Space Robot to Approach a Tumbling Object for Capture with Uncertainties in the Boundary Conditions, in 2013 AIAA GNC Conference, 2013: .direction through CoM of sys; .No consideration of the angular momentum management 
%- see Yang paper in $ICRA2016_VT/LITERATURE$
%- see Romano paper in $ICRA2016_VT/LITERATURE$
%- see in $/home/lampo/LITERATURE/PAPERS/Journal_Target_Pi/LITERATURE$ - see Jan Peter's operrational space control paper $Operational_Space_Control_Nakanishi_2008.pdf$ in $ICRA2016_VT/LITERATURE$
%
%
%
\begin{figure}[t!]
\centering\includegraphics[angle=0,width=0.42\textwidth]{./figures/Motivation_Image}
\caption{The motion of the Target grasping point and of the robot end-effector are shwon for the model-based (solid line) and for the true (dotted line) cases.}
\label{fig:motivation}
%\vspace{-10pt}
\end{figure}
%
\subsection{Problem statement}
% 0.5 pp
%
In the grasping task of interest we assume that the Target has a known geometry, such that model-based computer vision pose estimation can be used. Its angular rate is limited here to 2 deg/s (due to hardware limitations, the limit for the rigidization phase is set to 1 deg/s). %to provide pose estimates between the Target body reference frame and the robot end-effector frame. 
The grasping point on the Target is predefined. %We assume that its motion may be predicted for motion planning purposes [isairas2005] %and is limited in the maximum angular rate modulous to 2 deg./s. (due to hardware limitations, the limit for the stabilization phase is 1 deg/s). %We also assume that the dynamic paratemers of the Target are given with some given level of uncertainty (note that these are identified for motion prediction purposes only to an arbitrary constant [isairas2010]).
%
The Chaser is not actuated (free-floating) and is initially in the same orbit as that of the Target with zero translational and angular velocities.
%space robot consists of a 7 DoF robot manipulator mounted on a free-floating base, the latter not having any GNC actuation active during the task execution. We assume here that the grasping point is in reach of the robot for the complete grasping task. As such, we assume that the Chaser station-keeping has placed the Chaser in the same orbit as that of the Target, in the -V-bar direction, see Fig. ???, with an accuracy of ?? cm, ?? deg., ?? cm/s and ?? deg/sec.. The chaser initially has zero momentum (for the general treatment of the case of non-zero initial momentum see [Ale]).

The grasping task itself is commonly divided into three phases: an approach phase, in which the robot end-effector is brought in the vicinity of the moving grasping point of the Target; a tracking phase, in which the end-effector follows the grasping point with the same velocity, while homing in onto it and closing the grasp; a rigidization phase, in which the relative velocity between the Chaser and the Target is brought to rest by a suitable control of the robot manipulator. 

A feasible trajectory to accomplish this task is provided by a motion planner, first described in~\cite{lampariello2013generating} and extended here. The motion planner relies on a prediction of the Target motion, which can be accomplished as described in~\cite{hillenbrand2005motion}~\cite{aghili2012prediction}. However, in order to complete the task, the tracking controller will initially need to deviate from the reference trajectory, given that the latter is model-based and will differ from the real-world conditions. This fact is shown pictorially in Fig.~\ref{fig:motivation}. Note that the gross motion of the motion planner is still maintained, in order to avoid motion constraints such as, for example, a singularity. 

Due to the deviation from the reference trajectory in the approach and tracking phases, the reference trajectory for the rigidization phase is adapted online, such that the deviation in joint space is recovered. This favours the fullfillment of joint position related constraints (collisions avoidance, singularity avoidance) throughout it. 
%
%It remains to be shown, as we do here, that the reference trajectory can be used by a tracking controller to accomplish the complete grasping task, to include the stabilization. The assumption is in fact that errors in the reference trajectory for the approach phase are sufficiently small. 
%
%If not, the reference trajectory for the stabilization phase may become unfeasible. In fact, while in the approach phase the visual servoing takes care of the necessary trajectory motification, in the stabilization phase, the robot joint controller returns to the reference trajectory, in order to ensure that joint position related constraints (collisions avoidance, singularity avoidance) are fullfilled throughout it. More wil be said about this in Section ???.
%
%In this way, by grossly tracking the reference trajectory the feasibility of the complete maneuver is guaranteed. As such, the end time of the stabilization phase need not be minimal, as suggested in [Aghili], since it is sufficient that the system remains in the vicinity of the planned trajectory, and may be chosen following a different cryterion. Minimum energy maneuvers can be considered as a viable alternative, since, as we will see, they are more robust to modelling errors and visual servo inaccuracies.
%
%Since we also want to be able to deal with a contingency case, for which an undesired impact between the robot and the Target may occur (CHECK need to demonstrate in experiments?), the feedback control method is based on impedance control. This allows to handle the case of an impact robustly, by suitably tuning the impedance []. Furthermore, the possibility of losing the Target after the impact is further greatly reduced by the visual servo.
%
%The aim of the experimental validation includes testing and analysis of the vision guidance (pose estimation), the robot planning, the robot controller, as well as taking imperfect attitude control and robot manipulator control into account. Differently to other works of this kind cited above, due to the macro-micro kinematic structure of our facility, we can include all these elements together in one test environment. Last but not least, the realistic nature of the uncertainty is enhanced in the experimental setup, by the latters's time discretization, time delays, kinematic modelling errors, etcetera. 
%
%Motivation for VS: uncertainty coming from motion prediction (+/- 10 cm in real system), LUT approximation (i.e. solution for desired point is not exact, but how much?), robot model uncertainties (<1 cm), robot controller positioning error (+/- 2 cm), GNC positioning error (+/- 5 cm), GNC velocity error (+/- ? cm/s - see DEOS), unmodelled disturbances (?) - need a scaling rationale: test sum of erros on 3m long robot to see what joint error is to be expected and scale error here accordingly, accounting fr nonlinearity, or validate tests in simulation just as much + look for trajectories for which this error is least visible in joint space!
%
%\section{Robot autonomy and on-orbit servicing}
%
%It is interesting to realize that, as mentioned in Section ??, two different control approaches are foreseable for the grasping task: the telepresence-based and the autonomy-based approaches. The dibate whether one can supersede the other is still open, since both have their benefits and flaws. The first can make use of the operator's intelligence, to include promptness in dealing with unexpected operational conditions and more robustness to adverse lighting conditions. At the same time, the benefit brought by a delayed force reflection (between 30ms and 600ms, for direct and Geo Relay links respectively) to an operator on ground, when executing the grasping of a tumbling Target, is still being investigated upon. Evidence of the difficulty for humans to generally perform this task is already provided in [Aghili's x2], although these used position-controlled robots with low controller sampling rates (check).
%
%On the other hand, autonomous systems are often favoured in industry-driven studies (see for example DEOS and eDeorbit) because of different reasons: the high bandwidth requirements of telepresence (DEOS); the fact that the round-trip-time needs to include the operator reaction time, typically taken to be one second, which in the case of a contingency during grasping may be decisive (eDeorbit); the communication window is limited in the case of a direct link, by the limited ground station coverage, as well as by the possibility of occlusion brought about by the same tumbling Target; communication through a geostationary relay satellite may pose hard challenges in the antenna pointing task, if the Chaser is in synchronized flight with the Target (eDeorbit); finally, the autonomous mode guarantees feasibility with respect to the non-intuitive stabilization task, which was not addressed in the telepresence approach to date.
%
%+ see arguments from Aghili in favour of autonomy.
%
\section{Methods}
\label{sec:methods}
%
In this Section we present the methods used to solve the grasping task, to include (CHECK) elements of the motion planning, the visual-servo-based tracking control used in the approach and the tracking phases and the joint-position-based tracking control used in the rigidization phase. The control system architecture is shown in Fig.~\ref{fig:blockdiagram}.
%
\begin{figure*}
\psfrag{text_tr}[cc][cc][\FontFigS]{\textbf{Target tracking}}
\psfrag{text_st}[cc][cc][\FontFigS]{\textbf{Rigidization}}
\psfrag{text_vs}[cc][cc][\FontFigS]{Visual Servo}
\psfrag{text_pd}[cc][cc][\FontFigS]{\small{\begin{tabular}{@{}l@{}} Compliant\\Controller\\(PD+nullspace\end{tabular}}}
\psfrag{text_pl}[cc][cc][\FontFigS]{\small{\begin{tabular}{@{}l@{}} Plant\\(Chaser\\+manipulator\\dynamics\end{tabular}}}
\psfrag{text_mp}[cc][cc][\FontFigS]{{\begin{tabular}{@{}l@{}} Motion\\Synthesizer \end{tabular}}}
\psfrag{text_js}[cc][cc][\FontFigS]{\small{\begin{tabular}{@{}l@{}} Joint-space\\Rigidization\\controller \end{tabular}}}
\psfrag{t1}[cc][cc][\FontFigS]{\small{\begin{tabular}{@{}l@{}} Camera\\Vision \end{tabular}}}
\psfrag{t2}[cc][cc][\FontFigS]{\small{\begin{tabular}{@{}l@{}} EKF\\Observer \end{tabular}}}
\psfrag{txt_k}[cc][cc][\FontFigS]{\small{\begin{tabular}{@{}l@{}} Kinematics\\(Base/manipulator) \end{tabular}}}
\psfrag{t4}[cc][cc][\FontFigS]{\small{$\begin{bmatrix}q(t_g)\\ \dot{q}(t_g)\end{bmatrix}$}}
\psfrag{EKF_out}[cc][cc][\FontFigS]{\small{$\hat{H}_{eg}$}}
\psfrag{cam}[cc][cc][\FontFigS]{\small{$H_{eg}$}}
\psfrag{ts}[cc][cc][\FontFigS]{\small{$10$ [Hz]}}
\psfrag{t_3}[cc][cc][\FontFigS]{\small{$\tau_{rig}$}}
\psfrag{mp_car}[cc][cc][\FontFigS]{\small{$\begin{bmatrix}H_{eg,ref}\\ V_{eg,ref}\end{bmatrix}$}}
\psfrag{t_5}[cc][cc][\FontFigS]{\small{$\begin{Bmatrix}V_{e} & \dot{q} & H_{e} & q\end{Bmatrix}$}}
\psfrag{mp_joint}[cc][cc][\FontFigS]{\small{$\begin{bmatrix}q_{ref}\\ \dot{q}_{ref}\end{bmatrix}$}}
\psfrag{vs_out}[cc][cc][\FontFigS]{\small{$\begin{bmatrix}H_{e,des}\\ V_{e,des}\end{bmatrix}$}}
\psfrag{cc_out}[cc][cc][\FontFigS]{\small{$\begin{bmatrix}\tau_{cart}\\ \tau_{null}\end{bmatrix}$}}
\psfrag{int}[cc][cc][\FontFigS]{$\int$}
\psfrag{V_e}[cc][cc][\FontFigS]{\small{$V_e$}}
\psfrag{H_e}[cc][cc][\FontFigS]{\small{$H_e$}}
\psfrag{j}[cc][cc][\FontFigS]{\small{$\begin{bmatrix}q\\ \dot{q}\end{bmatrix}$}}
\psfrag{H_T}[cc][cc][\FontFigS]{\small{$H_t$}}
\centering\includegraphics[angle=0,width=0.85\textwidth]{./figures/BlockDia1}
\caption{Control system architecture with...}
\label{fig:blockdiagram}
\end{figure*}
%
%\begin{figure*}
%\centering\includegraphics[angle=0,width=0.95\textwidth]{./figures/Block_diagram_stabiliz}
%\caption{Control block diagram for the stabilization phase.}
%\label{fig:blockdiagram2}
%\end{figure*}
%
%\subsection{Control system architecture - 0,5 pp}
%
%A block diagram of the control systems for the approach and tracking phase and for the stabilization phase are shown in Fig.~\ref{fig:blockdiagram} and Fig.~\ref{fig:blockdiagram2} respectively. 
%
%\subsubsection{Plant}
%The plant refers to the free-floating robot, consisting of a free-floating satellite base and a 7 DoF robot manipulator. The only actuators present are those of the robot joints, since the base is assumed to be non-actuated. The sensors include the position and torque sensors of the robot joints and a stereo-camera at the robot end-effector. The satellite states are assumed to be ideal (check).
%
%Define reference frames. inertia, body, end-effector, other.
%
%\subsubsection{Target}
%This block represents the simulation of the Target motion, including that of the predefined grasping point on it.
%
%\subsubsection{Motion synthesizer}
%The motion synthesizer receives the reference trajectory from the motion planner and interpolates the desired Cartesian pose and robot configuration in time. Note that this function runs on-board of the Chaser spacecraft, whereas the reference trajectory is generated on ground before the task is executed.
%
%\subsubsection{Robot controller and forward kinematics}
%This is the inner loop of the robot controller, which runs at a sampling time of 1KHz. It containts two elements to control both the Cartesian pose and the joint configuration in null space. The forward kinematics provides the current Cartesian pose of the robot end-effector through a forward kinematics computation. The robot controller then, based on the chosen control strategy (see Section ??), determines the control torques to be applied to the robot. The satellite states are assumed to be ideal (check).
%
%\subsubsection{Camera-based motion estimation}
%This block represents the computer vision algorithm which runs onboard at a slower sampling rate of 10Hz and which provides the current relative pose between the robot end-effector and the Target grasping point (check). 
%
%The connections between these blocks constitute the visual servo and will be addressed in Section ?? in detail.
%
\subsection{Motion planning and motion synthesizer}
% - 1 pp
%
\subsubsection{Approach and tracking phases}
The motion planning method described in Section~\ref{sec:related_work} and in detail in~\cite{lampariello2013generating} is extended here to account for the requirements stemming specifically from the visual tracking. It is in fact required that throughout the approach phase sufficient features of the Target are in view of the camera (e.g., the Target's solar panel on its top suface) and that the pixel velocity in the image remains low. These result in motion constraints, the first of which is treated with an inequality constraint on the pitch angle of the end-effector frame $\mathcal{E}$ relative to the inertial frame $\mathcal{I}$, referred to as $\phi{}_{e}$ (see Fig.~\ref{fig:facility}), defined as
\begin{equation}
\phi{}_{e}{}^{2} \leq \phi_{e \: mid}{}^{2} + \phi_{e \: delta}{}^{2},
\end{equation}
where $\phi_{e \: mid}$ is a parameter to define a middle value for $\phi{}_{e}$ and $\phi_{e \: delta}$ is a paremeter which relates to the field-of-view of the camera. 

Defining the pixel velocities in the $x$ and $y$ components of the end-effector frame $\mathcal{E}$ to be ${}^{e}v{}_{px, py}={}^{e}v{}_{y, x}{}^{et}\ / {}^{e}r{}_{z}{}^{et}$, an inequality constraint is also introduced as
\begin{equation}
\Delta {}^{e}v{}_{px, py}  \leq {}^{e}v{}_{px, py} \leq \Delta {}^{e}v{}_{px, py},
\end{equation}
where $\Delta {}^{e}v{}_{px, py}$ are parameters which relate to the pixel velocity limits in the camera image. 


In order to minimize the relative velocity between the robot end-effector and the Target, and therefore the pixel velocity in the camera image, the robot joints velocity at the end of the approach maneuver was defined to be equal to that given by the inverse kinematics of the tracking phase which follows. In this way, the transition between these to phases, unlike in~\cite{lampariello2013generating}, is more smooth and less prone to large pixel velocity values.

The output of the motion planner is judiciously defined to account for two important aspects. Firstly, a reference trajectory of the end-effector is defined relative to the grasping point frame on the Target, $[\MatO{H}{}_{eg, ref}, \MatO{V}{}_{eg, ref}]$. The tracking controller is designed to track this relative motion, where its pose is given by $\MatO{H}{}_{eg}=\MatO{H}{}_{eI}\MatO{H}{}_{Ig}$. This ensures that any error in $\MatO{H}{}_{eI}$ (tracking control errors, robot forward kinematic errors) and in $\MatO{H}{}_{Ig}$ (Target motion prediction errors) are intrinsically eliminated in following the desired relative motion $[\MatO{H}{}_{ge, ref}]$, which is independent of these uncertainties. Note however, that the motion of the robot relative to absolute space will deviate from the motion planning solution. This relates to the second aspect to be considered, namely that a reference trajectory is also provided in the joint space of the robot manipulator. As will be shown in Section ??? CHECK, the tracking control law contains a main term to minimize the Cartesian tracking error and a second term, projected in the null-space of the robot manipulator, to minimize the tracking error in joint space. This is to minimize the deviation of the robot motion in joint space from the feasible reference trajectory. The null-space term also cares for the kinematic redundancy of the robot manipulator. 

The motion planner cannot run online, due to its computational runtimes and to the lack of strict guarantees on convergence time. The motion synthesizer, which runs online, interpolates the outputs defined above, namely $[\MatO{H}{}_{eg, ref}{}_{i}, \MatO{V}{}_{eg, ref}{}_{i}], q_{ref}{}_{i}$, for $0 \leq i\leq N$, where $N$ is the number of output steps of the motion planning solution. 
%
\subsubsection{Rigidization phase}
\label{sec:rigidization}
%
In this phase, the offline motion planner provides a reference trajectory in joint space. The  tracking controller here is a joint space controller. The task is to rigidize the compound after the grasp, bringing the relative motion between the two satellites to zero. Given that only internal forces come into play, the angular momentum of the Target is shared with the Chaser and at the end of the maneuver the two satellites tumble with a new angular velocity, function of their total inertia. The cost function of the optimization problem is chosen to be the mechanical energy of the robot manipulator, in order to minimize its loads, i.e.
\begin{equation}
\MatO{\Gamma} = \int^{t_{rf}}_{t_{ri}} (\tau {}^{T}(t) \MatO{\dot{q}}(t)){}^{2} dt
\label{eq:cost}
\end{equation}
where $t_{ri}$ $t_{rf}$ are the initial and final times of the motion. 

In the online setting however a modification of the reference trajectory is necessary, to account for the deviation from the reference trajectory in the previous approach phase. Given that the trajectory is parameterized with a B-spline, the optimization parameters of the solution generated offline are still used to synthesize online a new rigidization trajectory, by modifying them with the measured initial robot manipulator joint states. Let the measured initial position and velocity for a given joint be $q_{0m}$ and $\dot{q}_{0m}$ respectively, and the B-spline parameters $q_i, 1 \leq i \leq N_B$. The modified parameters are then taken to be:
\begin{equation}
q_{i \: mod} =   q_i +  (q_0 - q_{0m} + \dot{q}_{0m} * ({t_{rf}}-{t_{ri}})/N_B) * (N_B-i)/N_B,
\end{equation}
where the second term accounts for the initial position deviation $q_0 - q_{0m}$ and the joint velocity at the initial time times the duration of the first B-spline segment, $({t_{rf}}-{t_{ri}})/N_B$, in which the spline cannot be modified. This effectively smoothly brings the joint configuration back to the one planned offline. As such, the fullfilment of the joint position related motion constraints is favoured. The chosen modification of the trajectory could however give rise to an increase in robot joint torques, since it implies pushing the Target onto the predicted trajectory. Note however, that the choice of the cost function in Eqn.~(\ref{eq:cost}) minimizes these, allowing for a larger margin from their limits.
%
%The optimization problem for the stabilization phase was treated in a similar way as the approach phase. The joint states were parameterized with B-slines and provided the initial conditions in position, velocity and acceleration (check) resulting at the end of the tracking phase. The final conditions on the joint states were only expressed for the joint velocities and accelerations, leaving the joint positions open for the optimizer to be determined, in function of the assigned cost function. Note that this point solves an open issue when only implenting a dissipating control law, to stabilize the compound. In fact, doing so firstly does not give any bound on the final position reached at the end of the motion and as such no guarantee that collisions are avoided. Secondly, due to noise in the system, a purely dissipative control law results in a continuously drifting system (check with Marco and add results later?). The number of parameters was increased, for better convergence performace. 
%
%Of notice here is also to realise that the choice of parameterizing the robot joints was favoured with respect to that of parameterizing the end-effector trajectory. This is firstly because the robot control needs joint position commands, which in our case are given directly from the solution, without having to revert to an inverse kinematics function, to great advantage of the motion synthesizer (see Section ??). The use of an inverse kinematics function is also generally not advisable for the case that a singularity is met (location not known and function of inertia distribution). In this case, the inverse of the Jacobian is undefined. However, we note that singulatities also provide numerical problems in the presented formulation, due to the fact that even in their vicinity, the joint velocities increase noticeably. The integration of the equations of motion of a free-floating system is very sensitive to large velocities, leading the necessity of an excessively small integrator step size. Check - show example in results?
%
%With regars to the cost function, we chose here to minimize the mechanical energy. We propose it as alternative to minimizing the end time given that we track the solution in joint position and as such guarantee the collision avoidance that could arise from any residual relative drif velocity between the two spacecrafts. Although minimizing the mechanical energy requires defining a final time, since the solution would otherwise push the end time to infinity, an arbitrary sensible value can be chosen by the user, after inspection of the first solutions. It is important to stress that the goal of the motion planner is first to provide a feasible solution. The optimality is then used to make the solutions more robust to the uncertainties. Finally, due to the highly nonlinear nature of the problem (check), a global search is performed, in order to find a (close to) global minimum for a given query. Although we do not address the task of generating a look-up table here, for any tumbling state of interest, we revert the reader to [IROSD2013] for further details on this point.
%
%21/12/2017: the chosen cost function for the rigidization is the integral of the product $tau*qd$. This is best to option to reduce the effort of the LBR! Only drwaback is that is does not look nice, i.e. the target rotates toward the chaser (did a global search and could not find any better solutions). The integral of the product $F_e*v_e$ could be an interesting alternative (given that it implies a solution where the target slows down along its path, without rotating toward the chaser) to minimize the risk of collision, although we can deal with that.
%
%
%End of current version
%
%
%Explain motion synthesizer - give details of on-line B-spline with on-line modification function of new robot joint states + Phillip, Marco + see how this can work on board for all required outputs to controller! Then explain how Cartesian trajectory could be modified with motion prediction during approach and how resulting cartesian reference trajectory could be perfectly updated to real motion (relative to the base body). But must chose to give preference to joint position error (which neglects target trajectory change, otherwise don't know where will end up) and possible collision avoidance or to Cartesian error and possible end-effector and joint torque error (show how this can grow, for a given trajectory error!). As such minimizing energy gives a smooth solution and as such a more robust solution to prediction errors, since far from the motion boundaries and not on the edge of them (optimal handling of uncertainties on the off-line generated motion plannign solutions). Favoured here avoiding singularities. Furthermore, say that for LBR on OOS-SIM 5 cm error are a lot, but for 3/4 m long arm not. 
%
%Say that: The presented method needs to be able to meet strict guarantees on the solution (such as the upper bound on the computation time), for the safety-critical application at hand (software ceritifcation processes also need to be considered). As such, all computations involving optimization algorithms have to be performed off-line on ground. 
%
%0. motion planning (Roberto):
%	v. say that opt. params for Chaser position are very important for good convergence properties - but add params in approach to improve convergence - to do!
%	vi. say about minimizing joint motion or joint motion in null-space for approach phase - see use of nullspace term in invkin (see dkin2!!!) - to reduce effect of friction in NS dynamics of real robot - talk to Christian.
%	vii. say that for LBR on OOS-SIM 5 cm error are a lot, but for 3/4 m long arm not.
%	viii. compare min energy solution to solution from $F_e=K_d * Deltax_dot$ (must implement), for different Chaser/Target mass ratios
%	ix. do global search for min energy or command given $v_e, omega_e$ to inv-kin to see solution
%	x. add $q_ddot$($tf_approach$) as parameters to minimize tau($0_tracking$)
%	xi. compare joint space to cartesian space stabilization solution approaches
%	x. the problem of extracting the optimal solution from the LUT is not addressed in any more detail here (see IROS 2013)
%
%In pp method?
%In the proposed method, a motion planner provides a reference trajectory to execute the task described above, details of which can be found in [IROS2013]. Of notice it the fact that the method in [IROS2013] is meant to firstly guarantee the feasibility of the task with respect to all motion constraints, described in Section??. This differes from any of the approaches described in Section???, since there many important constraints are either not treated exhaustively (e.g., joint position and velocity, the latter in view of dynamic singularities, the position of which for a ff 3D system with n dof and with load X on e-e cannot be predefined to date), implying that the explicit effect of a disturbance or uncertainty on the future evolution of the system is not taken into account, or only added in the cost function as a weighting term (e.g., line-of-sight of end-effector cameras, for which the useful Target features may be lost, with obviously negative consequences), thus not guaranteeing their fullfillment. Here instead, the method based on nonlinear optimization, guarantees the fullfillment of the constraints for the reference trajectory (at the chosen via points, of arbitrary number, sufficient for the task). Due to the highly non-linear nature of the problem, the presented method also provides a (near to) global optimimum, for a very wide range of cost functions, for example,  minimized for improvement of the robustness of the control method, to model uncertainties and sensor errors, by performing a global search for a given task. The method finally allows to represent the system in question in its full free-floating dynamic behaviour, without the need to reduce the Chaser dynamics to those of a fixed-based robot, for ease of resolution of the related optimal control problem. We will see in Section ??? that the stabilization task is in fact a momentum transfer problem, rather than a detumbling (or passivation?) problem, with useful consequences on the resulting solutions found. The tumbling of the compound after the stabilization is by no means an issue, when realizing that the minimization of the attitude has been solved with simple technological solutions, such as omnidirectional antennas and gymbal joints [DEOS]. The impelling need for robot autonomy for the grasping task was also made evident in [eDeorbit], underlining the need for full autonomy, for which a communication link in the critical grasping phase is not foreseen.
%+ In the same Figure, the necessity for a motion planner is underlined by showing how this deviates around a robot singularity, rather than going right through it, as a simple regulation controller would do.
%+ make clear statements about singularities: although inv kin methods can avoid them, we can't tell if the motion after them is then feasible anymore, given non-holonomic nature of Chaser dynamics + if cannot avoid them right during tracking, we have a problem + cannot represent them yet.
%+ The uncertainties are quantified and analysed here to some extent, to validate the truthfullness of the assumption. 
%+ This last point has required making a decision between prioritizing position related to force related constraints. The internal forces required for the adjustment of the trajectory in the stabilization phase are function of the tracking error in the approach phase, and as such unknown. The alternative would be to recompute the stabilization trajectory online in cartesian space and tranfer the unknown onto the final position reached by the robot... 
%+ The feasibility (region) is provided by the motion planner, not by the user [Aghili's ball]. 
%	
%
%
\subsection{Extended Kalman Filter (Model-based control)}
The Extended Kalman Filter (EKF) as a nonlinear observer is ubiquitous in all disciplines germane to this paper. It is a nonlinear observer in the sense that the model propagation is nonlinear whereas, the error injection is linear and hence the covariance time-propagation is performed through a linear approximation of the state dynamics. In the context of this paper, the EKF provides robustness to the tracking controller against incoming measurement outliers from the computer vision algorithm by ensuring Lipschitz continuity of the measurement. Due to its predictor-update structure, it also provides a state prediction which allows us to compensate for image-processing time-delays and ensure continuous control errors during occlusion or measurement failures caused by degenerate observability conditions. From a tracking controller perspective, the EKF also estimates the target velocities which can be used as a feed-forward term for the Visual Servo, without which, the controller design is constrained. 

In \cite{Aghili07}, an adaptive EKF variant was developed which used Laser-vision data for parameter and motion estimation. The authors used this variant for a Prediction-planning-execution approach controller in \cite{Aghili08}. In \cite{Dubowsky}, the authors implemented a cascade of two filters using range images for similar objectives of target state, shape and inertia estimation. In \cite{DLR01}, a long-term prediction method was adopted keeping autonomous grasping in focus. In \cite{RIS0}, a closed-loop control system was implemented for autonomous target tracking with visual servo and EKF as a part of the incremental inverse-kinematics controller. Based on the formalism presented in \cite{Aghili07}, an EKF architecture was developed in \cite{Selfthesis} and is implemented on the OOS-Sim facility.

The state of the target is defined by its inertial pose, $\mathbf{H}_T = \begin{bmatrix} R(q) & r \\ 0 & 1\end{bmatrix}$ where $q$ and $r$ are the quaternion representation of the Target's orientation and the $r$, the analogous position, relative to the inertial frame. The pose is driven by a mixed velocity representation $\mathbf{V}_t^m = \begin{bmatrix}\dot{r}\\ \omega^b\end{bmatrix}$, where the superfix $b$ and $m$ denote body and mixed velocity forms. \ref{fig:facility} CHECK

The dynamic system is modeled with the state, CHECK $x_a \mathbb{R}^{13} = \begin{bmatrix}
q^T r^T \omega^T \dot{r}^T
\end{bmatrix}^T$ as,

\begin{align}
\frac{d}{dt}\begin{bmatrix} \dot{q} \\ r \\ \omega \\ \dot{r}\end{bmatrix} = \begin{bmatrix}\frac{1}{2}\omega \otimes q \\ \dot{r} \\-\omega_\times I\omega \\ \Phi(n) \end{bmatrix} \label{eq_SysDyn}
\end{align}

where $\otimes$ denotes the quaternion multiplication tensor, $(.)_\times$ denotes the skew-symmetric form of $\mathbb{R}^3$ denoting the adjoint action of body angular velocity. $\Phi(n)$ depends on the mean anomaly ($n$) and is the linear approximation of orbital dynamics given by the Clohessy-Wiltshire equations. Since, for the tracking phase, the total time, $T < 20$ [sec], we assume this term to be absent.

In the multiplicative variant of the EKF, the quaternion state is maintained as a $3$-component vector $\delta q_v \in T_Q$, which is the tangential space to the quaternion manifold. A detailed treatise on such vector expressions was given in \cite{Markley}. In this text, the Modified Rodriguez Parameters (MRP), $a_p$ was chosen so that singularity is at $360$ \cite{Tweddle}. The tangential vector is related to the quaternion as follows,
\begin{align}
\dot{a}_p(q) = \frac{4}{1+q_0}q_v
\end{align}
\begin{align}
\frac{1}{16}\begin{bmatrix}
8a_p \\ 16 - a_p^Ta_p
\end{bmatrix}
\end{align}
The differential form for $a_p$ is given as,
\begin{align}
\dot{a}_p = \Big(-\frac{1}{2}\omega_\times + \frac{1}{8}\Big)a_p + \Big(1 - \frac{1}{16}a_p^Ta_p\Big)\omega	 
\end{align}


Among the alternatives for scaled inertia parameterization for zero-torque motion propagation, \cite[\S 4.6]{TweddlePhD} the $3$-parameter form proposed in \cite{Aghili07} is used. So, the angular dynamics can be rewritten as,
\begin{align}
 \dot{\omega} = \psi(\omega) =  \begin{bmatrix}
 p_x \omega_y \omega_z \\
  p_y \omega_x \omega_z \\
   p_z \omega_x \omega_y  
 \end{bmatrix}
\end{align}
 
which is assumed to have a linear approximation about the estimate, $\hat{\omega}$ given by,
\begin{align}
	\delta \dot{\omega} = \mathbf{M}\delta{\omega}
\end{align} where $M = \Big( \frac{\partial \psi(\omega)}{\partial \omega}\Big)_{\omega = \hat{\omega}}$ is a hollow matrix \cite{Aghili07}.

Finally, the linear approximation of the system \eqref{eq_SysDyn} is given in \cite[eq. 4.79]{TweddlePhD} as $\mathbb{R}^{12}$ form,
\begin{align}
\dot{x} = \mathbf{A}x + \mathbf{B}w
\end{align}

Based on \ref{fig:facility} CHECK, the measurement equation is given as,
\begin{align}
y = \begin{bmatrix}
r_c \\ \mu \end{bmatrix} = \begin{bmatrix}
\rho_c + R(\eta_c)(r + R(\eta_t)\rho_t) \\
\eta_t^*\otimes q \otimes \eta_c^*
\end{bmatrix}
\end{align}

The linear approximation for the measurement is derived many times \cite{Aghili07}, \cite{TweddlePhD}, \cite{Dubowsky}, and we avoid the derivation and state the formula as,
\begin{align}
y = \mathbf{H}x = \begin{bmatrix}
- R(\overline{q})\rho_{t_\times} & 0_{3,3} & 1_{3,3} & 0_{3,3}\\
 1_{3,3} &   & & 0_{3,9}
\end{bmatrix}
\end{align}

Since the Kalman Filter equations are standard, we do not explicitly write the prediction-update form. The interested reader is referred to \cite{Kalman} for seminal paper on equations. By using the aforementioned system of equations, the EKF was implemented with the Outlier-rejection (OR) scheme suggested in \cite{Selfpaper} to provide robustness against local outliers from the vision system.
%
\subsection{Visual Servo for Approach and Tracking Phases}
In the context of On-Orbit Servicing, although a target may be non-cooperative in terms of navigation aids, its model variance is more likely to be low. As a result, this volume of work focuses on being able to visually track a well identified object using the image-space measurements to reconstruct its pose information. Based on the model-based visual tracking and CHECK $EKF$'s results, this control law is used to provide a velocity and pose for the inner dynamics controller. Such an operational space control is known in vision-based control literature as Pose-based Visual Servo (PBVS) \cite{Chaumette}. Since, in this work, the benefits of controlling in a non-degenerate error-space ($SE(3)$) are assumed to be more rewarding than controlling in a projection space, the control is classified as a Position-based Visual Servo law which is nothing but CHECK The availability of a usable model also obviates the uncertainty induced in $2$-D projection space due to depth uncertainty. 

The error for the PBVS system is related to the output of the $EKF$ through the logarithm map of $\hat{\mathbf{H}}_{eg}$ described as $\log_G:SE(3)\rightarrow \mathfrak{se}(3)$. The kinematic tracking velocity $V_m =\begin{bmatrix}\dot{\rho}_m^T  &\omega^T\end{bmatrix}^T$ is given using the visual servo law. Firstly, the reference trajectory is used to compute a desired end-effector pose $H_{e,des} = (H_e\hat{H}_{eg}) H_{ge,ref}.$ CHECK
\begin{align}
 V_m = K_1 \log_G(H_{e,v}^{-1}H_{e,des})
\end{align}

where,  $\dot{H}_{e,v} = Ad_{R_{e,v}}V_m~ \forall H_{e,v}(n) = H_e$ and $n \in [1..k]$ are the EKF sample times. This virtual frame acts like a trajectory for the manipulator and is solved as an initial value problem between two camera sampling times.

Finally, a compliant controller is placed in cascade after the visual servo which acts upon the Cartesian error. The impedance error is a Cartesian error observed in the inertial frame and is denoted as,

\begin{align}
 e = \log_G(H_e^{-1}H_{e,v})
\end{align}
 
This is the Cartesian error used for the compliant PD control, $\mathcal{F}_e = -K_Pe - K_D\dot{e}$. From Marco's paper CHECK for free-floating dynamics, the stability of the PD controller is established. 

The corresponding joint torques are given as,
\begin{equation}
\tau = J_g^T\mathcal{F}_e + (1_{n,n}-{J_g}^TJ_g^{*^T})\Gamma
\end{equation}
where $\Gamma$ is given by
\begin{equation}
\Gamma = ??? CHECK
\end{equation}


%
%
%
% Hrishik
% Describe rational and method (equations) of visual servo
% Describe KF method, refer to existing literature (ASTRA?)
%
% Roberto
% Describe LWR impedance controller
% Describe null-space controller
%
%1. Control Visual Servo Approach (Hrishik, Roberto)
%        -i. describe how to command the planned trajectory to the visual servo (optimization offline on ground, what is done on-line on board?), such that it is grossely followed, both in Cartesian and in joint space, but at the same time corrected by the feedback controller, to account for modelling errors and other uncertainties.
%	0. The visual servo is described in detail, to include tuning of an inner-loop impedance controller with an outer-loop visual servo, in the approach and tracking phase.
%	i. updated DEOS block diagram (position and impedance control), feedforward term, other
%	ii. inputs from path planner - e-e trajectory, configuration trajectory for null space, other
%	iii. theory for tracking of relative motion
%	iv. theory for tracking of null-space -ask Christian/Alin
%	v. visual servo (computer vision, visual servoing)
%	vi. robot control method for ff robot (Jg) and tracking control; what is maximum allowed impedance of LWR?
%	vii. use of KF with preidentified model parameters, for CV failure (e.g., due to occlusions)
%	viii. The satellite states are assumed to be ideal - check which are needed: $r0, v0, ori_0, omega_0$, sampling time (3 Hz, 1 kHz), other
%	
