\subsection{Computer Vision for Approach and Tracking Phases}
%
% Nassir
%
% describe CV method, refer to existing references
% provide analysis to explain why CV fails, with reference to experiemental data (image sequences)
The visual pose estimation is based on work of~\cite{Drummond2002} which relies on a known object geometry. The algorithm consisits of sampling model contours and edge detection, followed by a local optimization of the 3D rigd-body transform. The re-projection error is then minmized to allign visible model contours and image edges using the Levenberg-Marquardt algorithm.
 %Related to this model matching approach is moving edges method~\cite{Comport2004} which differs from the former in contour samply strategy. The latter samples model contours in 2D, after projecting model lines on the image. These two approaches have their own advatnages and disadvantages which have been explored in~\cite{Comport2005}. While both approaches show similar performance, the former is easier to implement as it presents a direct and accurate formulation for minimizing the reprojection error from %3D to 2D~\cite{Oumer2015}. 
The complex tumbling motion of the target poses difficulty in visual tracking. In order to address this problem, a motion prediction scheme based on an extended kalman filter is integrated into the local optimization. The prediction here relies on a simple kinematic motion model, assuming constant frame to frame motion. Under this assumption, the visual tracker is able to cope with a relatively high image motion between two camera frames. Moreover, the short-term prediction scheme helps the visual tracker reduce the search space in order not to remain trapped in potential local optima during minimization of the cost function. \rev{If the tracker does remain trapped (see for example Fig.s~\ref{fig:fig_norm_errors} and~\ref{fig:states_EKF}), the algorithm needs to be reinitialized either with an external global detector or with the EKF presented in Section II.B CHECK. The latter in fact satisfies the realtime constraints and makes use of the dynamic model of the Target. This approach will be implemented in future work.} The qualitative tracking results are illustrated in Fig.~\ref{fig:TrackingImages}, with examplar tracked images from the approach and tracking phases. Those in red indicate the projections of the model contours onto the image edges at the estimated pose. The overlap of the model contours and image edges shows the successful tracking and pose estimation.
%
%\begin{figure}
%\centering
%\begin{subfigure}
%	\includegraphics[angle=0,width=0.95\textwidth]{./figures/frame0786_result_cam0}
%	\caption{approach}
%\end{subfigure}
%\begin{subfigure}
%	\includegraphics[angle=0,width=0.95\textwidth]{./figures/frame0849_result_cam0}
%	\caption{Tracking}
%\end{subfigure}
%\begin{subfigure}
%	\includegraphics[angle=0,width=0.95\textwidth]{./figures/frame0922_result_cam0}
%	\caption{Tracking}
%\end{subfigure}
%\begin{subfigure}
%	\includegraphics[angle=0,width=0.95\textwidth]{./figures/frame0954_result_cam0}
%	\caption{Tracking}
%\end{subfigure}
%\label{fig:TrackingImages}
%\caption{Exemplar images during visual tracking for approach and tracking phase. The overlay of the model contours and image edges shows the successful tracking and pose estimation. The %target features reduce significantly as the manipulator approaches close to grasping. The axes of the coordinate frame of grasping point is indicated in red, green and blue }
%\end{figure}


%
\begin{figure*}
\centering\includegraphics[angle=0,width=0.24\textwidth]{./figures/frame0786_result_cam0_xes}
\centering\includegraphics[angle=0,width=0.24\textwidth]{./figures/frame0849_result_cam0_xes}
\centering\includegraphics[angle=0,width=0.24\textwidth]{./figures/frame0922_result_cam0_xes}
\centering\includegraphics[angle=0,width=0.24\textwidth]{./figures/frame0954_result_cam0_xes}
\caption{Exemplar images during visual tracking for approach and tracking phase. The overlay of the model contours \rev{(in red)} and image edges shows the successful tracking and pose estimation. The axes of the coordinate frame of the grasping point $\{\mathcal{G}\}$ are indicated in red, green and blue. The target features reduce significantly at very close range because of gripper finger occlusion (black in the image) and camera field of view.}
\label{fig:TrackingImages}
\end{figure*}


%There exist, however a few cases where the visual tracking was not able to provide the required pose accuracy for the visual servoing. For example, the inherent vision-based %pose estimation problem assocociated to in-plane motion where lateral rotation estimation error is large, particularly when a partial surface of the target with planar geometry is momentarily visible in non perspective view. Moreover, the outliers due to occlusion and limited field of view poses tracking failure particularly at very close range, as shown in Fig.~\ref{fig:GraspingImages}. Fortunately, at this range the gripper is a few millimeters from the grasping point, hence the implemented motion predictor supports final grasping phase.

%\begin{figure}
%\centering
%\begin{subfigure}
%	\includegraphics[angle=0,width=0.95\textwidth]{./figures/frame0954_result_cam0}
%	\caption{approach}
%\end{subfigure}
%\begin{subfigure}
%	\includegraphics[angle=0,width=0.95\textwidth]{./figures/frame0955_result_cam0}
%	\caption{Tracking}
%\end{subfigure}
%\begin{subfigure}
%	\includegraphics[angle=0,width=0.95\textwidth]{./figures/frame0956_result_cam0}
%	\caption{Tracking}
%\end{subfigure}
%\label{fig:GraspingImages}
%\caption{Failure cases of the visual tracking. At very close range, the visible target features are not sifficient for pose estimation because of occlusion (black in the images) and  %reduced field of view}
%\end{figure}

%\begin{figure*}
%\centering\includegraphics[angle=0,width=0.24\textwidth]{./figures/frame0954_result_cam0}
%\centering\includegraphics[angle=0,width=0.24\textwidth]{./figures/frame0955_result_cam0}
%\centering\includegraphics[angle=0,width=0.24\textwidth]{./figures/frame0956_result_cam0}
%\caption{Failure cases of the visual tracking. At very close range, the visible target features are not sifficient for pose estimation because of occlusion (black in the images) and  reduced field of view.}
%\label{fig:GraspingImages}
%\end{figure*}

% ---- You may menstion this in future work section-----
%In the future, the performance of the visual tracking will be improved, addressing problems related to in-plane motion, local minima and large image pixel velocity by integrating dynamic motion model of the coupled satellite-manipulator system for long-term prediction. Moreover, the visual tracking will be validated in a representative space environment with proper lighting conidtion as in~\cite{OumerPhdThesis}.

%	i. The visual servo also includes a pose estimation algorithm, which relies on a predefined simplifies model of the Target - show image with simplified model of the target

%
\subsection{Joint Tracking Control for Stabilization Phase}
%
% Roberto or Marco
% Describe tracking controller
% 
The tracking controller for the rigidization phase is described in Fig.~\ref{fig:blockdiagram}. The motion synthesizer provides an input expressed as $q_{r}, \dot{q}_{r}$. \rek{The PD+ control law for the tracking controller \cite{Paden} adopted here is then as follows}
\rek{
\begin{equation}
\begin{split}
\MatO{\tau}{}_{rig} =& \hat{\mathbf{M}}_{m,t}(\mathbf{q},\mathbf{x}_b)\ddot{\mathbf{q}}_{r} +  \tilde{\mathbf{C}}_{m,t}(\mathbf{q},\dot{\mathbf{q}},\mathbf{x}_b,\dot{\mathbf{x}}_b)\dot{\mathbf{q}}_{r}\\ &+ \MatO{K}{}_{p} (\mathbf{q}_{r}-\mathbf{q}) + \MatO{K}{}_{d} (\dot{\mathbf{q}}{}_{r}-\dot{\mathbf{q}})
\label{eq:rigidiz_control}
\end{split}
\end{equation}}
where $\MatO{K}{}_{p}, ~k_{p,ii} > 0$ and $\MatO{K}{}_{d},~k_{d,ii} > 0, ~\forall~i = [1..7]$ are (7x7) diagonal matrices including the stiffness and damping gains respectively and\rek{, $\hat{\mathbf{M}}_{m,t}$ and $\tilde{\mathbf{C}}_{m,t}$ are inertia and Coriolis matrices computed by adding the transformed target inertia to $\hat{\mathbf{M}}_m(\mathbf{q},\mathbf{x}_b)$ and $\tilde{\mathbf{C}}_m(\mathbf{q},\dot{\mathbf{q}},\mathbf{x}_b,\dot{\mathbf{x}}_b)$ respectively from eq.~\eqref{eq_reduced_dyn_js}. Note that, this is based on the assumption that the target CoM is the new end-effector frame}. The \rek{third} proportional term plays an \rek{important} role, since it brings the system into a feasible final configuration, as dictated by the motion planner. 
 
 


%
%
%
%
\section{Experimental facility}
% Roberto
%	i. introduce falicity
%	ii. describe extensions: target motion, post-grasping tumbling motion
%	iii. 4N/1Nm (CHECK) deadband in Target FTS - removed after grasping
%	iv. End-effector pads to avoid slipage (?)
%
The OOS-SIM experimental facility is described in detail in~\cite{7139588}. %Some new features were implemented to perform the grasping task of a rotating Target. The motion of the Target was allowed in all of its six degrees of freedom, by means of the online integration of its equations of motion (single rigid body) and the input to this from a force/torque sensor at the base of the Target mockup. Due to the sensor noise and to uncertainty in the gravity compensation of the sensor signal for the mockup weight (approx. 30 kg), a deadband filter was used in the approach and tracking phase in all three Cartesian directions. The filter was however removed at the moment of gripper closure and for the subsequent rigidization phase.
%
\rev{However, in order to simulate the motion of the two satellites after the grasp, a new approach was used, based on the conservation of momentum. We note, in fact, that after the grasp the forces of interaction between the Target and the Light-Weight Robot (LWR CHECK) are internal and, as such, do not alter the total momentum of the Chaser-LWR-Target system. Based on the measured relative pose between the Target and the LWR, the dynamic model of the Chaser-LWR multibody system is updated at the time of grasping (end of closure of gripper), $t_{ri}$,  to modify the inertial properties of the LWR's end-effector, to include those of the Target. From this point on, the laws of conservation of momentum are integrated in time, in function of the measured LWR joint positions and their first derivatives, as follows. Given the relationship between the twist of the Chaser $\MatO{\dot{x}}{}_{e}$ and the velocity of the LWR robot joints as~\cite{siciliano2016springer}}
\begin{equation}
\MatO{M}{}_{b} \MatO{\dot{x}}{}_{e} + \MatO{M}{}_{bm} \MatO{\dot{q}} = \MatO{L}
\label{eq:mom_cons}
\end{equation}
\rev{where $\MatO{L}$ is the constant total momentum, we first note that the latter is assumend to be zero before the grasp. At $t=t_{stab}$, matrices $\MatO{M}{}_{m}$ and $\MatO{M}{}_{bm}$ are modified to include the modelling of the Target. The left-hand side is also updated to be equal to the measured momentum of the Target. Assuming that there is no impact at the grasp, the current state of the system is then valid as initial conditions for integrating Eq. CHECK~(\ref{eq:mom_cons}) in $\MatO{\dot{x}}{}_{e}$, i.e.,}
\begin{equation}
\int_{t_{ri}}^{t_{ri}+t} \MatO{\dot{x}}{}_{e} \: \text{d}t = \int_{t_{ri}}^{t_{ri}+t} \MatO{M}{}_{b\;mod}^{-1} \left( \MatO{L}{}_{mod} -  \MatO{M}{}_{bm\;mod} \: \MatO{\dot{q}} \right) \: \text{d}t
\end{equation}
\rev{which provides the pose $\MatO{H}{}_{e}$ to be commanded to the OOS-SIM industrial robot which simulates the Chaser. The Target was then commanded to followed the Light-Weight Robot through the internal actions which the latter imparted on it. These, as done in~\cite{7139588}, were sensed by the FTS at the base of the Target and given as input to the online integration of its equations of motion.}

\rev{With this approach we do not use the FTS of the Chaser to determine its motion, as done in~\cite{7139588}, thus eliminating sources of simulation error. In fact, the FTS signal is affected by modelling errors (since the signal has to be corrected by the LWR gravity term) as well as by drift (due to sensor noise). We still use the FTS to determine the motion of the Target, since the inaccuracy of the forward kinematics of the facility does not favour a position control approach.}
%
%
%
%
%
%
\section{Results}
\label{sec:results}
%
%
%
%
% 1 pp
%
\begin{figure}[t!]
\psfrag{qd}[cc][cc][\FontFigB]{$\MatO{\dot{q}}$ [deg/s]}
\psfrag{t}[cc][cc][\FontFigB]{$t$ [s]}
\centering\includegraphics[angle=0,width=0.42\textwidth]{./figures/Joint_vel_2degs_2}
\caption{Simulated robot manipulator joint velocities for a Target spin velocity of 2 deg/s. The transition between the phases, at t=15~s and at t=18.5~s, is smooth. The jump during the tracking phase is due to the homing-in motion, which is however directed towards the target and, as such, does not have a noticeable effect on the pixel velocity in the camera image.}
\label{fig:Joint_vel_2degs}
%\vspace{-10pt}
\end{figure}
%
Fig.~\ref{fig:Joint_vel_2degs} shows the motion planner solution for a Target spin velocity of 2 deg/s. The figure shows the three phases of the maneuver. The transition from the approach to the tracking phase is smooth, as the end-effector alligns itself with the grasping point on the Target. The values of the parameters $\phi_{e \: mid}$ and $\phi_{e \: delta}$  were set to 40 and 7.5 deg respectively. The tracking phase lasts 3.5 seconds to allow for the gripper to close onto it. The rigidization phase \rev{starts after the Target is fully grappled and} lasts five seconds and the number of parameters per joint was $N_B=6$. The solution resulted from a global search,  which found different local minima, as expected, due to nonlinearity of the optimization problem. 

%The control gains were defined as ... $K_p$, $K_d$, nullspace K. The deadband filter of the Target force/torque sensor signals were set to 4N and 1Nm.

%
\begin{figure}[t!]
\psfrag{q}[cc][cc][\FontFigB]{$\MatO{q}-\MatO{q}{}_{ref}$ [deg]}
\psfrag{t}[cc][cc][\FontFigB]{$t$ [s]}
\centering\includegraphics[angle=0,width=0.42\textwidth]{./figures/joint_space_motion_2subplots_2}
\caption{Measured robot manipulator joint position error for Target spin velocity of 1 deg/s (top) and 2 deg/s (bottom). For the latter case, only the approach phase is shown, in which however the use of the EKF and of the extended parameterization of the joint motion give a net increase in joint-space tracking performance.}
\label{fig:joint_space_motion_2subplots}
%\vspace{-10pt}
\end{figure}
%
%
\begin{figure}[t!]
\psfrag{xx}[cc][cc][\FontFigB]{$\MatO{\omega}{}_{t}$ [deg/s]}
\psfrag{yy}[cc][cc][\FontFigB]{$\MatO{\phi}{}_{t}$ [deg/s]}
\psfrag{t}[cc][cc][\FontFigB]{$t$ [s]}
\centering\includegraphics[angle=0,width=0.42\textwidth]{./figures/Target_motion}
\caption{Measured Target angular velocity (top) and orientation (bottom) for the 1 deg/s case. The post-grasping tumbling of the sattellite stack is visible in the (reduced) rotation about the $x$-axis.}
\label{fig:Target_motion}
%\vspace{-10pt}
\end{figure}
%

Fig.~\ref{fig:joint_space_motion_2subplots} shows the measured robot manipulator joint position error, defined as $\MatO{q}-\MatO{q}{}_{ref}$, for the cases of Target spin velocities of 1 deg/s and 2 deg/s respectively. In the experiments on the OOS-SIM facility it was in fact found that the rigidization task for the 2 deg/s case was intractable with the current setup. \rev{CHECK need motivation} As such the experimental results presented here for the rigidization phase only relate to the 1 deg/s case. In Fig.~\ref{fig:Target_motion} the measurement of the Target motion is shown, in which we observed a very slow damping of the angular velocity. \rev{The oscillations in the angular velocity appear to have two frequencies: the lower one is to be attributed to the imepdance control of the LWR; the higher one is to be attributed to the time delay and discretization effects in the control loop of the facility (independent of the LWR impedance parameters).}

%Furthermore, the inertial parameters of the two satellites used in the facility model were increased with respect to ideal values. This was done in order to limit the velocities commanded to the industrial robots. The values taken here were.... chaser, target inertias, L

Returning to Fig.~\ref{fig:joint_space_motion_2subplots}, the error in the joint position is shown to improve substantially for the second case, due to the fact that the EKF and the joint motion parameterization shown in Fig.~\ref{fig:Joint_vel_2degs} is used (the manuever was not possible without these new features). While the first provides a smoother estimate of $\MatO{H}{}_{ge}$ (as shown below), the latter reduces the pixel velocity by a factor of two. At the point of transition between the tracking and the rigidization phase ($t=18.5$), the joint position error becomes zero, due to the recomputation of the reference trajectory (see Section\ref{sec:rigidization}). The tracking error in the rigidization phase is then shown to remain small.

In Figures~\ref{fig:fig_norm_errors} the output error norm of the position $r_c$ of EKF and vision is compared with respect to the ground truth. The EKF error norm is plotted as a heat-map of the statistical metrix, $\chi^2$ of the incoming vision data. It is observed that the $\chi^2$ measure degrades (yellow) for $t > 0 $ and $||r_c|| \rightarrow 0 $. In Fig.~\ref{fig:fig_norm_errors}, the degradation of vision data culminates in measurement failures (marked as rectangular area) towards the end. The EKF estimates though stay bounded. Fig.~\ref{fig:states_EKF} shows the velocity convergence of the filter. It also demonstrates the orientation degradation as $||r_c|| \rightarrow 0$. This observation betrays a general problem with the eye-in-hand configuration of visual servoing, since, in close proximity to target, the observability degeneracy degrades camera-based measurement. 
%
\begin{figure}[t!]
\psfrag{y1}[cc][cc][\FontFigB]{$||\Delta r_c||^2$}
\psfrag{y2}[cc][cc][\FontFigB]{$||\Delta r_c||^2$}
\psfrag{leg1}[cc][cc][\FontFigM]{$EKF$}
\psfrag{leg2}[cc][cc][\FontFigM]{$Vision$}
\psfrag{x}[cc][cc][\FontFigM]{$EKF$}
\psfrag{y}[cc][cc][\FontFigM]{$Vision$}
\psfrag{t}[cc][cc][\FontFigB]{$t$[sec]}
\psfrag{ekf}[cc][cc][\FontFigM]{$EKF$}
\psfrag{vision}[cc][cc][\FontFigM]{$Vision$}
\centering\includegraphics[angle=0,width=0.47\textwidth]{./figures/fig_norm_errors}
\caption{Comparison of direct-Vision measurements with EKF, based on the norm $||\Delta r_c^2||$. As $||r_c|| \rightarrow 0$, the statistical measure of fitness, $\chi^2 \rightarrow \infty $ eventually leading to pose estimation failures due to degenerate observability.}
\label{fig:fig_norm_errors}
%\vspace{-10pt}
\end{figure}
%
%
\begin{figure}[t!]
\psfrag{om}[cc][cc][\FontFigB]{$\omega$}
\psfrag{omhat}[cc][cc][\FontFigB]{$\hat{\omega}$}
\psfrag{true}[cc][cc][\FontFigB]{$\omega$}
\psfrag{t2}[cc][cc][\FontFigB]{$t$[sec]}
\psfrag{t1}[cc][cc][\FontFigB]{$t$[sec]}
\psfrag{qua}[cc][cc][\FontFigB]{$\mu$}
\psfrag{qhat}[cc][cc][\FontFigB]{$\hat{\mu}{}_{KF}$}
\psfrag{vision}[cc][cc][\FontFigB]{$\mu_V$}
\centering\includegraphics[angle=0,width=0.48\textwidth]{./figures/states_EKF}
\caption{a) Target state estimation ($\omega$) in EKF for tracking control. b) Divergence of visual tracking's orientation estimate towards end of maneuver.}
\label{fig:states_EKF}
%\vspace{-10pt}
\end{figure}
%
\section{Discussion and Conclusion}
\label{sec:disc}
%
The main achivement of this paper is to demonstrate the feasibility of a grasping strategy based on Target motion prediction, robot motion planning and trajectory tracking, specifically for the latter step. In fact, due to modelling uncertainties, the true trajectory deviates from the reference trajectory in joint space. The latter is therefore partially adapted online for the rigidizaiton phase. A method is presented and validated here, which does that while favouring joint position related motion constraints. The tracking controller is then shown to succesfully perform the task. In this way, the feasible (and optimal) motion planning solutions,  \rev{which describe trajectories for the full degrees of freedom of the system throughout the approach and rigidization phases, and which are} computed offline with much computational effort, are shown to be useful for control purposes. %The reference trajectories are computed taking a complete three-dimensional multibody dynamics model into consideration, without simplifying assumptions.
%
%We also argue that a reference trajectory based method provides greater robustness than local control methods. The control method must provide a guarantee that the grasping point can be tracked at all times and that the rigidization phase which follows remains feasible. Local control (e.g., potential) methods generally cannot provide this guarantee. Free-floating robots are known to possess dynamic singularities, which are function of the related distribution of its inertia. Their position in joint space, for the multibody system of interest here, is not only to the author's knowledge not representable, but is also variable in time during the robot's operations, due to changes in the inertial distribution. 

A second major achievement of this paper is the implementation of an Extended Kalman Filter \rev{in between the visual tracker and the visual servo in cascade with an impedance controller. This} ensures a Lipschitz continuity of measurements during the robot motion CHECK (make clear why this is not a trivial engineering step), making the control method robust for executing the grasping task. It is in fact shown that the visual tracking algorithm adoped may become degenerate in the vicinity of the Target (CHECK but Aghili does this too). Furthermore, the new formulation to reduce the computational footprint has been shown to give a signifcant improvement (CHECK where?). %Finally, given that the visual servo along with manipulator dynamics is known to lose passivity in presence of target motion [], the computation of the reference trajectory provides the necessary feedforward terms which ensure passivity unter the assumption of no modelling errors. This is complemented by the estimate of the Target velocity provided by the Kalman filter, as shown in Fig.\ref{fig:states_EKF}. As a result, the overall system is passive in the absence of external torques on the Target.

%A limitation of the presented method is however also recognized. We argued, in fact, that the modelling uncertainties are small and as such, by grossly tracking the reference trajectory, the feasibility of the complete maneuver is guaranteed. In reality, the reference trajectory is only feasible at predefined via points along it, given the time discretization of the optimal control problem. This does not say anything about the feasibility of the solution in its vicinity. Future work will need to address this robustness issue, given that the tracking controller departs from the reference trajectory to account for the uncertainties. 

The momentum-based approach on the OOS-SIM facility has proven to be efficient in reducing drift due to noise and modelling errors. Future work will be dedicated to improving its performance in the coupled configuration. Furthermore, the stability of complete interconnected system will be addressed. Finally, the sensing of the Chaser, to include typical sensor noise and sampling times, will be considered.
%
%
%"In this way, by grossly tracking the reference trajectory the feasibility of the complete maneuver is guaranteed. As such, the end time of the stabilization phase need not be minimal, as suggested in [Aghili], since it is sufficient that the system remains in the vicinity of the planned trajectory, and may be chosen following a different cryterion. Minimum energy maneuvers can be considered as a viable alternative, since, as we will see, they are more robust to modelling errors and visual servo inaccuracies."
%
%Following target trajectory and slowing it down does not take account of chaser inertia. Providing a MBS solution vs Aghili's single rigid body solution.
%
%The satellite states are assumed to be ideal
%
%
%\section{Videos}
%1. simulation - bernhard
%2. facility
%@unknown{unknown,
%author = {Isabel Ribeiro, Maria and Ribeiro, Isabel},
%year = {2004},
%month = {04},
%pages = {},
%title = {Kalman and Extended Kalman Filters: Concept, Derivation and Properties}
%}
